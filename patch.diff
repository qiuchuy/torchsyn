diff --git a/nnsmith/cli/torch_program_gen.py b/nnsmith/cli/torch_program_gen.py
deleted file mode 100644
index d65330e..0000000
--- a/nnsmith/cli/torch_program_gen.py
+++ /dev/null
@@ -1,117 +0,0 @@
-import logging
-import os
-import random
-import time
-
-import hydra
-from omegaconf import DictConfig
-
-from nnsmith.abstract.extension import activate_ext
-from nnsmith.backends.factory import BackendFactory
-from nnsmith.backends.pt2 import PT2
-from nnsmith.graph_gen import SymbolicGen, model_gen, viz
-from nnsmith.logging import MGEN_LOG
-from nnsmith.materialize import Model, TestCase, Render
-from nnsmith.materialize.torch import TorchModelCPU
-from nnsmith.narrow_spec import auto_opset
-from nnsmith.util import hijack_patch_requires, mkdir, op_filter
-
-
-@hydra.main(version_base=None, config_path="../config", config_name="torch_main")
-def main(cfg: DictConfig):
-    # Generate a random ONNX model
-    # TODO(@ganler): clean terminal outputs.
-    mgen_cfg = cfg["mgen"]
-
-    seed = random.getrandbits(32) if mgen_cfg["seed"] is None else mgen_cfg["seed"]
-
-    export_program_path = mgen_cfg["torch_program_path"]
-
-    MGEN_LOG.info(f"Using seed {seed}")
-
-    # TODO(@ganler): skip operators outside of model gen with `cfg[exclude]`
-    model_cfg = cfg["model"]
-    ModelType = Model.init(model_cfg["type"], backend_target=cfg["backend"]["target"])
-    ModelType.add_seed_setter()
-
-    if cfg["backend"]["type"] is not None:
-        factory = BackendFactory.init(
-            cfg["backend"]["type"],
-            target=cfg["backend"]["target"],
-            optmax=cfg["backend"]["optmax"],
-            parse_name=True,
-        )
-    else:
-        factory = None
-
-    # GENERATION
-    opset = auto_opset(
-        ModelType,
-        factory,
-        vulops=mgen_cfg["vulops"],
-        grad=mgen_cfg["grad_check"],
-    )
-    opset = op_filter(opset, mgen_cfg["include"], mgen_cfg["exclude"])
-    hijack_patch_requires(mgen_cfg["patch_requires"])
-    activate_ext(opset=opset, factory=factory)
-
-    tgen_begin = time.time()
-    gen = model_gen(
-        opset=opset,
-        method=mgen_cfg["method"],
-        seed=seed,
-        max_elem_per_tensor=mgen_cfg["max_elem_per_tensor"],
-        max_nodes=mgen_cfg["max_nodes"],
-        timeout_ms=mgen_cfg["timeout_ms"],
-        rank_choices=mgen_cfg["rank_choices"],
-        dtype_choices=mgen_cfg["dtype_choices"],
-    )
-    tgen = time.time() - tgen_begin
-
-    if isinstance(gen, SymbolicGen):
-        MGEN_LOG.info(
-            f"{len(gen.last_solution)} symbols and {len(gen.solver.assertions())} constraints."
-        )
-
-        if MGEN_LOG.getEffectiveLevel() <= logging.DEBUG:
-            MGEN_LOG.debug("solution:" + ", ".join(map(str, gen.last_solution)))
-
-    # MATERIALIZATION
-    tmat_begin = time.time()
-    ir = gen.make_concrete()
-
-    MGEN_LOG.info(
-        f"Generated DNN has {ir.n_var()} variables and {ir.n_compute_inst()} operators."
-    )
-
-    mkdir(mgen_cfg["save"])
-    if cfg["debug"]["viz"]:
-        fmt = cfg["debug"]["viz_fmt"].replace(".", "")
-        viz(ir, os.path.join(mgen_cfg["save"], f"graph.{fmt}"))
-
-    model = ModelType.from_gir(ir)
-    model.refine_weights()  # either random generated or gradient-based.
-    model.set_grad_check(mgen_cfg["grad_check"])
-    oracle = model.make_oracle()
-    render = Render()
-    render.emit_input(model)
-    render.emit_model(model)
-    # render.emit_backend(model)
-    rendered = render.render()
-    tmat = time.time() - tmat_begin
-
-    tsave_begin = time.time()
-    testcase = TestCase(model, oracle)
-    testcase.dump(root_folder=mgen_cfg["save"])
-    tsave = time.time() - tsave_begin
-
-    MGEN_LOG.info(
-        f"Time:  @Generation: {tgen:.2f}s  @Materialization: {tmat:.2f}s  @Save: {tsave:.2f}s"
-    )
-
-    with open(export_program_path, "w") as f:
-        f.write(rendered)
-
-
-if __name__ == "__main__":
-    main()
diff --git a/nnsmith/config/torch_main.yaml b/nnsmith/config/torch_main.yaml
deleted file mode 100644
index 05a019a..0000000
--- a/nnsmith/config/torch_main.yaml
+++ /dev/null
@@ -1,70 +0,0 @@
-model:
-  type: torch
-  path: "???" # can be multiple files tho.
-
-mgen: # model gen.
-  max_nodes: 5
-  timeout_ms: 10000
-  vulops: False
-  method: "symbolic-cinit"
-  save: "nnsmith_output"
-  seed: null
-  max_elem_per_tensor: 65536 # 2^16
-  rank_choices: null # 0 ~ __MAX_RANK__
-  dtype_choices: null # 0 ~ __MAX_DTYPE__
-  include: null # ops to include; example mgen.include="[core.NCHWConv2d, core.ReLU]"
-  exclude: null # ops to exclude;
-  patch_requires: [] # files that with @patch_requires
-  grad_check: false # additionally check gradients
-  torch_program_path: ../../../generated/torch_program.py
-
-# backend config
-backend:
-  type: null
-  optmax: true
-  target: "cpu"
-
-ad:
-  type: null
-
-cache:
-  topset: true # Run dtype test with automatically maintained cache
-
-debug:
-  viz: false
-  viz_fmt: "png" # or "svg" for much smaller figure size and precision;
-
-fuzz:
-  time: 14400
-  root: "???"
-  seed: null
-  crash_safe: false
-  test_timeout: null
-  save_test: null
-
-filter:
-  type: []
-  patch: []
-
-cmp:
-  equal_nan: true # skip regarding it as a bug if with fp exception values.
-
-  raw_input: null # path to raw input data (Dict[str, np.ndarray])
-
-  oracle: "auto"
-  # "auto": use `oracle.pkl` in local path;
-  # PathLike: get the oracle from somewhere else;
-  # null: fallback to random.
-
-  with:
-    type: null
-    optmax: true
-    target: "cpu"
-
-  seed: null
-  bug_presence: "report" # or "crash"
-  save: null # path to save the bug report if `bug_presence` is "report"
-
-defaults:
-  - override hydra/job_logging: file
-  - override hydra/hydra_logging: colorlog
diff --git a/nnsmith/util.py b/nnsmith/util.py
index de675e3..84f46e9 100644
--- a/nnsmith/util.py
+++ b/nnsmith/util.py
@@ -51,7 +51,7 @@ def set_seed(seed: int, names: List = None):
         SEED_SETTERS[name](seed)
 
 
-def mkdir(dir: os.PathLike, yes=True):
+def mkdir(dir: os.PathLike, yes=False):
     if os.path.exists(dir):
         decision = ""
         if yes:
diff --git a/setup.cfg b/setup.cfg
index 438f048..ee0e3a4 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -43,4 +43,3 @@ console_scripts =
     nnsmith.dtype_test = nnsmith.cli.dtype_test:main
     nnsmith.fuzz = nnsmith.cli.fuzz:main
     nnsmith.report_syn = nnsmith.cli.report_syn:main
-    nnsmith.torch_program_gen = nnsmith.cli.torch_program_gen:main      
