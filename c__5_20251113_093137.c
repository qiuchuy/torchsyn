/*
 * Generated C Neural Network Program
 * Generated by NNSmith C Backend
 */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <time.h>
#include <stdbool.h>



// Tensor utility functions with raw pointers
int compute_tensor_size(const int* shape, int ndims) {
    int size = 1;
    for (int i = 0; i < ndims; i++) {
        size *= shape[i];
    }
    return size;
}

int get_tensor_offset(const int* shape, const int* indices, int ndims) {
    int offset = 0;
    int stride = 1;
    for (int i = ndims - 1; i >= 0; i--) {
        offset += indices[i] * stride;
        stride *= shape[i];
    }
    return offset;
}

float* allocate_tensor(const int* shape, int ndims) {
    int size = compute_tensor_size(shape, ndims);
    return (float*)malloc(size * sizeof(float));
}

void free_tensor(float* data) {
    if (data) {
        free(data);
    }
}

// Helper functions for common tensor shapes
int get_tensor_rank(float* tensor) {
    // For simplicity, we'll pass rank as a separate parameter
    // This function is just for compatibility
    return 1;
}

void get_tensor_shape(float* tensor, int* shape, int ndims) {
    // Shape will be passed separately as parameters
    // This function is just for compatibility
}


// Addition operation: c = a + b (element-wise)
void op_add(const float* a, const float* b, float* c, int size) {
    // Assume broadcasting is handled by NNSmith to match shapes
    for (int i = 0; i < size; i++) {
        c[i] = a[i] + b[i];
    }
}

// Subtraction operation: c = a - b (element-wise)
void op_sub(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = a[i] - b[i];
    }
}

// Multiplication operation: c = a * b (element-wise)
void op_mul(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = a[i] * b[i];
    }
}

// Division operation: c = a / b (element-wise)
void op_div(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = a[i] / b[i];
    }
}


// ReLU activation
void op_relu(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = fmaxf(0.0f, x[i]);
    }
}

// Sigmoid activation
void op_sigmoid(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = 1.0f / (1.0f + expf(-x[i]));
    }
}

// Tanh activation
void op_tanh(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = tanhf(x[i]);
    }
}


// Sum reduction along all dimensions
float op_sum(const float* x, int size) {
    float sum = 0.0f;
    for (int i = 0; i < size; i++) {
        sum += x[i];
    }
    return sum;
}

// Mean reduction along all dimensions
float op_mean(const float* x, int size) {
    float sum = 0.0f;
    for (int i = 0; i < size; i++) {
        sum += x[i];
    }
    return sum / size;
}


// Matrix multiplication: C = A * B
void op_matmul(const float* a, const float* b, float* c, int M, int K, int N) {
    // Assume 2D matrices: a[M][K], b[K][N], c[M][N]
    // Initialize to zero
    for (int i = 0; i < M * N; i++) {
        c[i] = 0.0f;
    }

    // Matrix multiplication
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            for (int k = 0; k < K; k++) {
                c[i * N + j] += a[i * K + k] * b[k * N + j];
            }
        }
    }
}


// 2D Convolution (simplified)
void op_conv2d(const float* input, const float* weight, const float* bias, float* output,
               int N, int H_in, int W_in, int C_in,
               int H_k, int W_k, int C_out,
               int stride_h, int stride_w, int pad_h, int pad_w) {
    // input: [N, H, W, C_in], weight: [H_k, W_k, C_in, C_out], bias: [C_out], output: [N, H_out, W_out, C_out]
    int H_out = (H_in + 2 * pad_h - H_k) / stride_h + 1;
    int W_out = (W_in + 2 * pad_w - W_k) / stride_w + 1;

    // Initialize to zero
    int output_size = N * H_out * W_out * C_out;
    for (int i = 0; i < output_size; i++) {
        output[i] = 0.0f;
    }

    // Convolution computation
    for (int n = 0; n < N; n++) {
        for (int h_out = 0; h_out < H_out; h_out++) {
            for (int w_out = 0; w_out < W_out; w_out++) {
                for (int c_out = 0; c_out < C_out; c_out++) {
                    float sum = 0.0f;
                    for (int h_k = 0; h_k < H_k; h_k++) {
                        for (int w_k = 0; w_k < W_k; w_k++) {
                            for (int c_in = 0; c_in < C_in; c_in++) {
                                int h_in = h_out * stride_h - pad_h + h_k;
                                int w_in = w_out * stride_w - pad_w + w_k;

                                if (h_in >= 0 && h_in < H_in && w_in >= 0 && w_in < W_in) {
                                    int input_idx = ((n * H_in + h_in) * W_in + w_in) * C_in + c_in;
                                    int weight_idx = ((h_k * W_k + w_k) * C_in + c_in) * C_out + c_out;
                                    sum += input[input_idx] * weight[weight_idx];
                                }
                            }
                        }
                    }
                    int output_idx = ((n * H_out + h_out) * W_out + w_out) * C_out + c_out;
                    output[output_idx] = sum + bias[c_out];
                }
            }
        }
    }
}


// Round operation
void op_round(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = roundf(x[i]);
    }
}

// Floor operation
void op_floor(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = floorf(x[i]);
    }
}

// Ceil operation
void op_ceil(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = ceilf(x[i]);
    }
}

// Absolute value
void op_abs(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = fabsf(x[i]);
    }
}

// ReduceMin along all dimensions
float op_reducemin(const float* x, int size) {
    if (size <= 0) return 0.0f;
    float min_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] < min_val) {
            min_val = x[i];
        }
    }
    return min_val;
}

// ReduceMax along all dimensions
float op_reducemax(const float* x, int size) {
    if (size <= 0) return 0.0f;
    float max_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] > max_val) {
            max_val = x[i];
        }
    }
    return max_val;
}

// Constant operation (initialize with value)
void op_constant(float* y, int size, float value) {
    for (int i = 0; i < size; i++) {
        y[i] = value;
    }
}

// Reshape operation (just copy data, shape is handled separately)
void op_reshape(const float* x, float* y, int size) {
    memcpy(y, x, size * sizeof(float));
}

// Expand operation (broadcast to larger tensor)
void op_expand(const float* x, float* y, int input_size, int output_size) {
    for (int i = 0; i < output_size; i++) {
        y[i] = x[i % input_size];
    }
}

// Slice operation
void op_slice(const float* x, float* y, const int* input_shape, const int* output_shape,
              const int* start_indices, int ndims) {
    // Simplified slice - assumes contiguous memory
    int output_size = 1;
    for (int i = 0; i < ndims; i++) {
        output_size *= output_shape[i];
    }

    for (int i = 0; i < output_size; i++) {
        y[i] = x[i]; // Simplified - should calculate proper indices
    }
}

// Transpose operation (2D)
void op_transpose_2d(const float* x, float* y, int H, int W) {
    for (int i = 0; i < H; i++) {
        for (int j = 0; j < W; j++) {
            y[j * H + i] = x[i * W + j];
        }
    }
}

// Element-wise minimum
void op_min(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (a[i] < b[i]) ? a[i] : b[i];
    }
}

// Element-wise maximum
void op_max(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (a[i] > b[i]) ? a[i] : b[i];
    }
}

// Clip operation
void op_clip(const float* x, float* y, int size, float min_val, float max_val) {
    for (int i = 0; i < size; i++) {
        if (x[i] < min_val) {
            y[i] = min_val;
        } else if (x[i] > max_val) {
            y[i] = max_val;
        } else {
            y[i] = x[i];
        }
    }
}

// Generic transpose for N-dimensional tensors (simplified)
void op_transpose(const float* x, float* y, const int* input_shape, const int* perm, int ndims) {
    // Simplified: for now just copy data
    // Full implementation would need to calculate proper indices based on permutation
    int total_size = 1;
    for (int i = 0; i < ndims; i++) {
        total_size *= input_shape[i];
    }
    memcpy(y, x, total_size * sizeof(float));
}

// Atan operation
void op_atan(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = atanf(x[i]);
    }
}

// Cast to boolean (0 or 1)
void op_cast_bool(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = (x[i] != 0.0f) ? 1.0f : 0.0f;
    }
}

// Reflect padding (simplified - just copy input)
void op_reflect_pad(const float* x, float* y, int input_size, int output_size, const int* pads) {
    // Simplified implementation: just copy input to beginning of output
    memcpy(y, x, input_size * sizeof(float));
    // Zero out the padded regions
    for (int i = input_size; i < output_size; i++) {
        y[i] = 0.0f;
    }
}

// Expand in last 4 dimensions
void op_expand_last4(const float* x, float* y, int input_size, int output_size) {
    // Simplified: repeat input pattern
    for (int i = 0; i < output_size; i++) {
        y[i] = x[i % input_size];
    }
}

// Sin operation
void op_sin(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = sinf(x[i]);
    }
}

// Cos operation
void op_cos(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = cosf(x[i]);
    }
}

// Log operation
void op_log(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = logf(x[i]);
    }
}

// Exp operation
void op_exp(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = expf(x[i]);
    }
}

// Sqrt operation
void op_sqrt(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = sqrtf(x[i]);
    }
}

// Cast to int32 (simplified - just round to nearest int and back to float)
void op_cast_i32(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = (float)((int32_t)roundf(x[i]));
    }
}

// Triu (upper triangular matrix) - simplified: just copy input
void op_triu(const float* x, float* y, int rows, int cols) {
    // Simplified implementation: just copy the entire matrix
    // Full implementation would zero out lower triangular part
    for (int i = 0; i < rows * cols; i++) {
        y[i] = x[i];
    }
}

// Neg operation
void op_neg(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = -x[i];
    }
}

// Reciprocal operation
void op_reciprocal(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = (x[i] != 0.0f) ? 1.0f / x[i] : 0.0f;
    }
}

// Greater than operation
void op_greater(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (a[i] > b[i]) ? 1.0f : 0.0f;
    }
}

// Less than operation
void op_less(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (a[i] < b[i]) ? 1.0f : 0.0f;
    }
}

// Equal operation
void op_equal(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (fabsf(a[i] - b[i]) < 1e-6f) ? 1.0f : 0.0f;
    }
}

// Power operation
void op_pow(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = powf(a[i], b[i]);
    }
}

// GELU activation
void op_gelu(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = 0.5f * x[i] * (1.0f + tanhf(x[i] * 0.70710678f));  // Simplified GELU
    }
}

// Leaky ReLU
void op_leaky_relu(const float* x, float* y, int size, float negative_slope) {
    for (int i = 0; i < size; i++) {
        y[i] = (x[i] >= 0.0f) ? x[i] : negative_slope * x[i];
    }
}

// PReLU (parameterized ReLU)
void op_prelu(const float* x, const float* alpha, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = (x[i] >= 0.0f) ? x[i] : alpha[i] * x[i];
    }
}

// Softmax
void op_softmax(const float* x, float* y, int size, int axis) {
    // Simplified softmax on entire tensor
    float max_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] > max_val) max_val = x[i];
    }

    float sum = 0.0f;
    for (int i = 0; i < size; i++) {
        y[i] = expf(x[i] - max_val);
        sum += y[i];
    }

    for (int i = 0; i < size; i++) {
        y[i] /= sum;
    }
}

// Asin operation
void op_asin(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = asinf(x[i]);
    }
}

// Acos operation
void op_acos(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = acosf(x[i]);
    }
}

// Tan operation
void op_tan(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = tanf(x[i]);
    }
}

// Log2 operation
void op_log2(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = log2f(x[i]);
    }
}

// MaxPool2d (simplified)
void op_maxpool2d(const float* x, float* y, int batch, int channels, int height, int width,
                   int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_h, int pad_w) {
    // Very simplified implementation - just copy input to output
    int output_size = batch * channels * height * width;
    for (int i = 0; i < output_size; i++) {
        y[i] = x[i];
    }
}

// AvgPool2d (simplified)
void op_avgpool2d(const float* x, float* y, int batch, int channels, int height, int width,
                   int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_h, int pad_w) {
    // Very simplified implementation - just copy input to output
    int output_size = batch * channels * height * width;
    for (int i = 0; i < output_size; i++) {
        y[i] = x[i];
    }
}

// Squeeze operation (remove dimensions of size 1)
void op_squeeze(const float* x, float* y, int input_size) {
    memcpy(y, x, input_size * sizeof(float));
}

// Unsqueeze operation (add dimension of size 1)
void op_unsqueeze(const float* x, float* y, int input_size) {
    memcpy(y, x, input_size * sizeof(float));
}

// ReduceProd
float op_reduceprod(const float* x, int size) {
    if (size <= 0) return 0.0f;
    float prod = 1.0f;
    for (int i = 0; i < size; i++) {
        prod *= x[i];
    }
    return prod;
}

// ArgMin (returns index of minimum value)
int op_argmin(const float* x, int size) {
    if (size <= 0) return 0;
    int min_idx = 0;
    float min_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] < min_val) {
            min_val = x[i];
            min_idx = i;
        }
    }
    return min_idx;
}

// ArgMax (returns index of maximum value)
int op_argmax(const float* x, int size) {
    if (size <= 0) return 0;
    int max_idx = 0;
    float max_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] > max_val) {
            max_val = x[i];
            max_idx = i;
        }
    }
    return max_idx;
}

// Cast to float32
void op_cast_f32(const float* x, float* y, int size) {
    memcpy(y, x, size * sizeof(float));
}

// Cast to float64 (simplified - just copy)
void op_cast_f64(const float* x, float* y, int size) {
    memcpy(y, x, size * sizeof(float));
}

// Cast to int64
void op_cast_i64(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = (float)((int64_t)x[i]);
    }
}

// Logical AND
void op_and(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = ((a[i] != 0.0f) && (b[i] != 0.0f)) ? 1.0f : 0.0f;
    }
}

// Logical OR
void op_or(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = ((a[i] != 0.0f) || (b[i] != 0.0f)) ? 1.0f : 0.0f;
    }
}

// Logical XOR
void op_xor(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        bool a_val = a[i] != 0.0f;
        bool b_val = b[i] != 0.0f;
        c[i] = (a_val ^ b_val) ? 1.0f : 0.0f;
    }
}

// Where operation (conditional selection)
void op_where(const float* condition, const float* x, const float* y, float* output, int size) {
    for (int i = 0; i < size; i++) {
        output[i] = (condition[i] != 0.0f) ? x[i] : y[i];
    }
}

// Concat operations (simplified - just concatenate)
void op_concat1(const float** inputs, float* output, const int* input_sizes, int num_inputs) {
    int offset = 0;
    for (int i = 0; i < num_inputs; i++) {
        memcpy(output + offset, inputs[i], input_sizes[i] * sizeof(float));
        offset += input_sizes[i];
    }
}

// BatchNorm2d (simplified - just copy input)
void op_batchnorm2d(const float* x, const float* gamma, const float* beta,
                     const float* mean, const float* var, float* y, int size) {
    // Simplified implementation: just copy input
    memcpy(y, x, size * sizeof(float));
}

// Interpolation operations (simplified - just copy)
void op_nearest_interp(const float* x, float* y, int input_size, int output_size) {
    memcpy(y, x, input_size * sizeof(float));
    // Zero out remaining elements if output is larger
    for (int i = input_size; i < output_size; i++) {
        y[i] = 0.0f;
    }
}

void op_linear_interp(const float* x, float* y, int input_size, int output_size) {
    op_nearest_interp(x, y, input_size, output_size);
}

void op_bilinear_interp(const float* x, float* y, int input_size, int output_size) {
    op_nearest_interp(x, y, input_size, output_size);
}

void op_bicubic_interp(const float* x, float* y, int input_size, int output_size) {
    op_nearest_interp(x, y, input_size, output_size);
}

void op_trilinear_interp(const float* x, float* y, int input_size, int output_size) {
    op_nearest_interp(x, y, input_size, output_size);
}

// Conv1d (simplified - just copy)
void op_conv1d(const float* input, const float* weight, const float* bias, float* output,
                int batch, int in_channels, int out_channels, int input_size, int kernel_size,
                int stride, int padding) {
    // Simplified: just copy input to output
    int output_size = batch * out_channels * input_size;
    memcpy(output, input, output_size * sizeof(float));
}

// NCHWConv2d (simplified - just copy)
void op_nchw_conv2d(const float* input, const float* weight, const float* bias, float* output,
                     int batch, int in_channels, int out_channels, int height, int width,
                     int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_h, int pad_w) {
    // Simplified: just copy input to output
    int output_size = batch * out_channels * height * width;
    memcpy(output, input, output_size * sizeof(float));
}

// Tril (lower triangular)
void op_tril(const float* x, float* y, int rows, int cols) {
    // Simplified: just copy the entire matrix
    // Full implementation would zero out upper triangular part
    for (int i = 0; i < rows * cols; i++) {
        y[i] = x[i];
    }
}

// ConstPad (constant padding)
void op_const_pad(const float* x, float* y, int input_size, int output_size, float pad_value) {
    memcpy(y, x, input_size * sizeof(float));
    for (int i = input_size; i < output_size; i++) {
        y[i] = pad_value;
    }
}

// ReplicatePad
void op_replicate_pad(const float* x, float* y, int input_size, int output_size) {
    for (int i = 0; i < output_size; i++) {
        y[i] = x[i < input_size ? i : input_size - 1];
    }
}

// Additional operator implementations for completeness

// ReduceL1 (L1 norm)
float op_reducel1(const float* x, int size) {
    float sum = 0.0f;
    for (int i = 0; i < size; i++) {
        sum += fabsf(x[i]);
    }
    return sum;
}

// ReduceL2 (L2 norm)
float op_reducel2(const float* x, int size) {
    float sum_sq = 0.0f;
    for (int i = 0; i < size; i++) {
        sum_sq += x[i] * x[i];
    }
    return sqrtf(sum_sq);
}

// Sign operation
void op_sign(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        if (x[i] > 0.0f) {
            y[i] = 1.0f;
        } else if (x[i] < 0.0f) {
            y[i] = -1.0f;
        } else {
            y[i] = 0.0f;
        }
    }
}

// IsNan operation
void op_isnan(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = isnan(x[i]) ? 1.0f : 0.0f;
    }
}

// IsInf operation
void op_isinf(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = isinf(x[i]) ? 1.0f : 0.0f;
    }
}

// IsFinite operation
void op_isfinite(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = isfinite(x[i]) ? 1.0f : 0.0f;
    }
}

// Logical Not
void op_not(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = (x[i] == 0.0f) ? 1.0f : 0.0f;
    }
}

// GreaterThanOrEqual
void op_greater_equal(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (a[i] >= b[i]) ? 1.0f : 0.0f;
    }
}

// LessThanOrEqual
void op_less_equal(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (a[i] <= b[i]) ? 1.0f : 0.0f;
    }
}

// NotEqual
void op_not_equal(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (fabsf(a[i] - b[i]) >= 1e-6f) ? 1.0f : 0.0f;
    }
}

// Remainder operation
void op_remainder(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        if (b[i] != 0.0f) {
            c[i] = fmodf(a[i], b[i]);
        } else {
            c[i] = 0.0f;  // Handle division by zero
        }
    }
}

// FloorDivide operation
void op_floor_divide(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        if (b[i] != 0.0f) {
            c[i] = floorf(a[i] / b[i]);
        } else {
            c[i] = 0.0f;  // Handle division by zero
        }
    }
}

// Bitwise shift left (simplified for floats)
void op_left_shift(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        int shift = (int)b[i];
        if (shift >= 0 && shift < 32) {
            c[i] = (float)((int)a[i] << shift);
        } else {
            c[i] = 0.0f;
        }
    }
}

// Bitwise shift right (simplified for floats)
void op_right_shift(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        int shift = (int)b[i];
        if (shift >= 0 && shift < 32) {
            c[i] = (float)((int)a[i] >> shift);
        } else {
            c[i] = 0.0f;
        }
    }
}

// Bitwise AND (simplified for floats)
void op_bitwise_and(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (float)((int)a[i] & (int)b[i]);
    }
}

// Bitwise OR (simplified for floats)
void op_bitwise_or(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (float)((int)a[i] | (int)b[i]);
    }
}

// Bitwise XOR (simplified for floats)
void op_bitwise_xor(const float* a, const float* b, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (float)((int)a[i] ^ (int)b[i]);
    }
}

// Bitwise NOT (simplified for floats)
void op_bitwise_not(const float* a, float* c, int size) {
    for (int i = 0; i < size; i++) {
        c[i] = (float)(~(int)a[i]);
    }
}

// Erf operation (Error function)
void op_erf(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = erff(x[i]);
    }
}

// Erfc operation (Complementary error function)
void op_erfc(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = erfcf(x[i]);
    }
}

// Log10 operation
void op_log10(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = log10f(x[i]);
    }
}

// Log1p operation (log(1 + x))
void op_log1p(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = log1pf(x[i]);
    }
}

// Expm1 operation (exp(x) - 1)
void op_expm1(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = expm1f(x[i]);
    }
}

// Square operation
void op_square(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = x[i] * x[i];
    }
}

// Cube operation
void op_cube(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = x[i] * x[i] * x[i];
    }
}

// Rsqrt operation (reciprocal square root)
void op_rsqrt(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        if (x[i] > 0.0f) {
            y[i] = 1.0f / sqrtf(x[i]);
        } else {
            y[i] = 0.0f;  // Handle non-positive input
        }
    }
}

// Softplus operation
void op_softplus(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        if (x[i] > 15.0f) {  // Avoid overflow
            y[i] = x[i];
        } else if (x[i] < -15.0f) {  // Avoid underflow
            y[i] = 0.0f;
        } else {
            y[i] = log1pf(expf(x[i]));
        }
    }
}

// Silu operation (Swish: x * sigmoid(x))
void op_silu(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        float sigmoid_x = 1.0f / (1.0f + expf(-x[i]));
        y[i] = x[i] * sigmoid_x;
    }
}

// Hardswish operation
void op_hardswish(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        float relu6_plus_3 = fmaxf(0.0f, fminf(6.0f, x[i] + 3.0f));
        y[i] = x[i] * relu6_plus_3 / 6.0f;
    }
}

// Mish operation
void op_mish(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        float softplus_x = (x[i] > 15.0f) ? x[i] : ((x[i] < -15.0f) ? 0.0f : log1pf(expf(x[i])));
        float tanh_softplus = tanhf(softplus_x);
        y[i] = x[i] * tanh_softplus;
    }
}

// Hardtanh operation
void op_hardtanh(const float* x, float* y, int size, float min_val, float max_val) {
    for (int i = 0; i < size; i++) {
        if (x[i] < min_val) {
            y[i] = min_val;
        } else if (x[i] > max_val) {
            y[i] = max_val;
        } else {
            y[i] = x[i];
        }
    }
}

// Hardshrink operation
void op_hardshrink(const float* x, float* y, int size, float lambd) {
    for (int i = 0; i < size; i++) {
        if (x[i] > lambd || x[i] < -lambd) {
            y[i] = x[i];
        } else {
            y[i] = 0.0f;
        }
    }
}

// Softshrink operation
void op_softshrink(const float* x, float* y, int size, float lambd) {
    for (int i = 0; i < size; i++) {
        if (x[i] > lambd) {
            y[i] = x[i] - lambd;
        } else if (x[i] < -lambd) {
            y[i] = x[i] + lambd;
        } else {
            y[i] = 0.0f;
        }
    }
}

// Relu6 operation
void op_relu6(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        y[i] = fmaxf(0.0f, fminf(6.0f, x[i]));
    }
}

// Elu operation
void op_elu(const float* x, float* y, int size, float alpha) {
    for (int i = 0; i < size; i++) {
        if (x[i] >= 0.0f) {
            y[i] = x[i];
        } else {
            y[i] = alpha * (expf(x[i]) - 1.0f);
        }
    }
}

// Celu operation
void op_celu(const float* x, float* y, int size, float alpha) {
    for (int i = 0; i < size; i++) {
        if (x[i] >= 0.0f) {
            y[i] = x[i];
        } else {
            y[i] = alpha * (expf(x[i] / alpha) - 1.0f);
        }
    }
}

// Selu operation
void op_selu(const float* x, float* y, int size) {
    const float alpha = 1.6732632423543772848170429916717f;
    const float scale = 1.0507009873554804934193349852946f;

    for (int i = 0; i < size; i++) {
        if (x[i] >= 0.0f) {
            y[i] = scale * x[i];
        } else {
            y[i] = scale * alpha * (expf(x[i]) - 1.0f);
        }
    }
}

// Glu operation (Gated Linear Unit)
void op_glu(const float* x, float* y, int size, int dim) {
    // Simplified GLU: splits input along dim and multiplies
    for (int i = 0; i < size / 2; i++) {
        float gate = 1.0f / (1.0f + expf(-x[i + size / 2]));
        y[i] = x[i] * gate;
    }
}

// HardSigmoid operation
void op_hardsigmoid(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        float val = (x[i] + 3.0f) / 6.0f;
        y[i] = fmaxf(0.0f, fminf(1.0f, val));
    }
}

// LogSigmoid operation
void op_logsigmoid(const float* x, float* y, int size) {
    for (int i = 0; i < size; i++) {
        // For numerical stability
        if (x[i] > 0.0f) {
            y[i] = -log1pf(expf(-x[i]));
        } else {
            y[i] = x[i] - log1pf(expf(x[i]));
        }
    }
}

// Softmin operation
void op_softmin(const float* x, float* y, int size, int axis) {
    // Softmin = softmax(-x)
    float max_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] > max_val) max_val = x[i];
    }

    float sum = 0.0f;
    for (int i = 0; i < size; i++) {
        y[i] = expf(-(x[i] - max_val));
        sum += y[i];
    }

    for (int i = 0; i < size; i++) {
        y[i] /= sum;
    }
}

// LogSoftmax operation
void op_logsoftmax(const float* x, float* y, int size, int axis) {
    float max_val = x[0];
    for (int i = 1; i < size; i++) {
        if (x[i] > max_val) max_val = x[i];
    }

    float sum = 0.0f;
    for (int i = 0; i < size; i++) {
        y[i] = expf(x[i] - max_val);
        sum += y[i];
    }

    float log_sum = logf(sum);
    for (int i = 0; i < size; i++) {
        y[i] = x[i] - max_val - log_sum;
    }
}


// Main model function declaration
void model_forward(float** inputs, float** outputs,
                       const int** input_shapes, const int** output_shapes,
                       const int* input_ndims, const int* output_ndims);




// Weight initialization for model
void initialize_model_weights() {
    // In practice, this would load weights from a file or initialize them

    // Example weight initialization
    // float conv_weight_data[] = {...};
    // float conv_bias_data[] = {...};

    // Load weights into the model
    // This would be specific to your model architecture
}




// Input initialization for testing
void initialize_test_inputs(float** input_data, const int** input_shapes, int* input_ndims) {

    // Static shape arrays (could be made dynamic)

static int input_shape_0[] = {29};
static int input_shape_1[] = {1};



    // Input 0: v11_0 (shape: 29)
    input_shapes[0] = input_shape_0;
    input_ndims[0] = 1;
    input_data[0] = (float*)malloc(29 * sizeof(float));

    // Initialize with random values or test data
    for (int j = 0; j < 29; j++) {
        input_data[0][j] = (float)rand() / RAND_MAX;  // Random [0, 1]
    }


    // Input 1: v4_0 (shape: 1)
    input_shapes[1] = input_shape_1;
    input_ndims[1] = 1;
    input_data[1] = (float*)malloc(1 * sizeof(float));

    // Initialize with random values or test data
    for (int j = 0; j < 1; j++) {
        input_data[1][j] = (float)rand() / RAND_MAX;  // Random [0, 1]
    }


}




// Graph execution for model
void model_forward(float** inputs, float** outputs,
                       const int** input_shapes, const int** output_shapes,
                       const int* input_ndims, const int* output_ndims) {
    // inputs[0..1]: input tensor data (raw pointers)
    // outputs[0..2]: output tensor data (raw pointers)
    // Shape information is passed separately

    // Variable declarations for intermediate tensors

    float* v_0;
    float* v_1;
    float* v_2;
    float* v_3;
    float* v_4;
    float* v_5;
    float* v_6;
    float* v_7;
    float* v_8;
    float* v_9;
    float* v_10;
    float* v_11;
    int v_0_shape[4];
    int v_0_ndim;
    int v_1_shape[4];
    int v_1_ndim;
    int v_2_shape[4];
    int v_2_ndim;
    int v_3_shape[4];
    int v_3_ndim;
    int v_4_shape[4];
    int v_4_ndim;
    int v_5_shape[4];
    int v_5_ndim;
    int v_6_shape[4];
    int v_6_ndim;
    int v_7_shape[4];
    int v_7_ndim;
    int v_8_shape[4];
    int v_8_ndim;
    int v_9_shape[4];
    int v_9_ndim;
    int v_10_shape[4];
    int v_10_ndim;
    int v_11_shape[4];
    int v_11_ndim;

    // inputs[0..1]: input tensor data (raw pointers)
    // outputs[0..2]: output tensor data (raw pointers)
    // Shape information is passed separately


    // Input v_0
    v_0 = inputs[0];
    v_0_shape[0] = 29;
    v_0_shape[1] = 1;
    v_0_shape[2] = 1;
    v_0_shape[3] = 1;
    v_0_ndim = 1;


    // Input v_1
    v_1 = inputs[1];
    v_1_shape[0] = 1;
    v_1_shape[1] = 1;
    v_1_shape[2] = 1;
    v_1_shape[3] = 1;
    v_1_ndim = 1;


    // Allocate v_2 (operation: Concat2)
    v_2 = (float*)malloc(30 * sizeof(float));
    v_2_shape[0] = 30;
    v_2_shape[1] = 1;
    v_2_shape[2] = 1;
    v_2_shape[3] = 1;
    v_2_ndim = 1;

    // Concat2: using simplified implementation

    op_concat1((const float*[]){v_1}, v_2, (int[]){30}, 1);


    // Allocate v_3 (operation: Concat1)
    v_3 = (float*)malloc(30 * sizeof(float));
    v_3_shape[0] = 30;
    v_3_shape[1] = 1;
    v_3_shape[2] = 1;
    v_3_shape[3] = 1;
    v_3_ndim = 1;

    // Concat1: using simplified implementation

    op_concat1((const float*[]){v_2}, v_3, (int[]){30}, 1);


    // Allocate v_4 (operation: Slice)
    v_4 = (float*)malloc(30 * sizeof(float));
    v_4_shape[0] = 30;
    v_4_shape[1] = 1;
    v_4_shape[2] = 1;
    v_4_shape[3] = 1;
    v_4_ndim = 1;

    // Slice: using simplified implementation

    op_slice(v_3, v_4, (int[]){1, 1}, (int[]){1, 1}, (int[]){0, 0}, 1);


    // Allocate v_5 (operation: Clip)
    v_5 = (float*)malloc(30 * sizeof(float));
    v_5_shape[0] = 30;
    v_5_shape[1] = 1;
    v_5_shape[2] = 1;
    v_5_shape[3] = 1;
    v_5_ndim = 1;

    op_clip(v_4, v_5, 30, 0.0f, 1.0f);


    // Allocate v_6 (operation: Abs)
    v_6 = (float*)malloc(30 * sizeof(float));
    v_6_shape[0] = 30;
    v_6_shape[1] = 1;
    v_6_shape[2] = 1;
    v_6_shape[3] = 1;
    v_6_ndim = 1;

    op_abs(v_5, v_6, 30);


    // Allocate v_7 (operation: CastF64)
    v_7 = (float*)malloc(30 * sizeof(float));
    v_7_shape[0] = 30;
    v_7_shape[1] = 1;
    v_7_shape[2] = 1;
    v_7_shape[3] = 1;
    v_7_ndim = 1;

    op_cast_f64(v_6, v_7, 30);


    // Allocate v_8 (operation: Tan)
    v_8 = (float*)malloc(30 * sizeof(float));
    v_8_shape[0] = 30;
    v_8_shape[1] = 1;
    v_8_shape[2] = 1;
    v_8_shape[3] = 1;
    v_8_ndim = 1;

    op_tan(v_7, v_8, 30);


    // Allocate v_9 (operation: PTMatMul)
    v_9 = (float*)malloc(1.0 * sizeof(float));
    v_9_shape[0] = 1;
    v_9_shape[1] = 1;
    v_9_shape[2] = 1;
    v_9_shape[3] = 1;
    v_9_ndim = 0;

    // MatMul: insufficient shape info, copying input

    memcpy(v_9, v_6, 1.0 * sizeof(float));


    // Allocate v_10 (operation: Min)
    v_10 = (float*)malloc(30 * sizeof(float));
    v_10_shape[0] = 30;
    v_10_shape[1] = 1;
    v_10_shape[2] = 1;
    v_10_shape[3] = 1;
    v_10_ndim = 1;

    op_min(v_9, v_6, v_10, 30);


    // Allocate v_11 (operation: CastI64)
    v_11 = (float*)malloc(1.0 * sizeof(float));
    v_11_shape[0] = 1;
    v_11_shape[1] = 1;
    v_11_shape[2] = 1;
    v_11_shape[3] = 1;
    v_11_ndim = 0;

    op_cast_i64(v_9, v_11, 1.0);

    // Copy output v0_0 to output buffer 0
    memcpy(outputs[0], v_8, 30 * sizeof(float));

    // Copy output v8_0 to output buffer 1
    memcpy(outputs[1], v_10, 30 * sizeof(float));

    // Copy output v3_0 to output buffer 2
    memcpy(outputs[2], v_11, 1.0 * sizeof(float));

    // Clean up intermediate tensors (excluding input tensors)
    if (v_2 != NULL) { free(v_2); }
    if (v_3 != NULL) { free(v_3); }
    if (v_4 != NULL) { free(v_4); }
    if (v_5 != NULL) { free(v_5); }
    if (v_6 != NULL) { free(v_6); }
    if (v_7 != NULL) { free(v_7); }
    if (v_8 != NULL) { free(v_8); }
    if (v_9 != NULL) { free(v_9); }
    if (v_10 != NULL) { free(v_10); }
    if (v_11 != NULL) { free(v_11); }
}

// Helper function to run the complete model
void run_model(float** input_data, const int** input_shapes, const int* input_ndims,
                   float** output_data, const int** output_shapes, int* output_ndims) {
    // Allocate output tensors
    for (int i = 0; i < 3; i++) {
        int output_size = compute_tensor_size(output_shapes[i], output_ndims[i]);
        output_data[i] = allocate_tensor(output_shapes[i], output_ndims[i]);
    }

    // Run forward pass
    model_forward(input_data, output_data, input_shapes, output_shapes, input_ndims, output_ndims);
}




int main() {
    printf("C Neural Network Program (Raw Pointers)\n");
    printf("======================================\n\n");

    // Initialize input data (using raw pointers)
    float* input_data[2];
    const int* input_shapes[2];
    int input_ndims[2];

    initialize_test_inputs(input_data, input_shapes, input_ndims);

    // Print input information
    printf("Input tensors:\n");

    printf("  Input 0 (v11_0): shape=[29], size=29\n");

    printf("  Input 1 (v4_0): shape=[1], size=1\n");

    printf("\n");

    // Initialize model weights
    initialize_model_weights();

    // Prepare output storage (using raw pointers)
    float* output_data[3];
    static int output_shape_arrays[3][4]; // Max 4D tensors
    const int* output_shapes[3];
    int output_ndims[3];

    // Set up output shapes

    // Output 0: v0_0
    static int output_shape_0[] = {30};
    output_shapes[0] = output_shape_0;
    output_ndims[0] = 1;

    // Output 1: v8_0
    static int output_shape_1[] = {30};
    output_shapes[1] = output_shape_1;
    output_ndims[1] = 1;

    // Output 2: v3_0
    static int output_shape_2[] = {};
    output_shapes[2] = output_shape_2;
    output_ndims[2] = 0;


    // Run the model
    printf("Running model inference...\n");
    clock_t start = clock();

    run_model(input_data, input_shapes, input_ndims,
              output_data, output_shapes, output_ndims);

    clock_t end = clock();
    double elapsed_time = ((double)(end - start)) / CLOCKS_PER_SEC;

    printf("Inference completed in %.6f seconds\n\n", elapsed_time);

    // Print outputs
    printf("Model outputs:\n");

    printf("  Output 0 (v0_0, shape: 30):\n");
    printf("  [");
    for (int j = 0; j < 30; j++) {
        printf("%.6f", output_data[0][j]);
        if (j < 30 - 1) printf(", ");
        if ((j + 1) % 8 == 0) printf("\n   ");
    }
    printf("]\n\n");

    printf("  Output 1 (v8_0, shape: 30):\n");
    printf("  [");
    for (int j = 0; j < 30; j++) {
        printf("%.6f", output_data[1][j]);
        if (j < 30 - 1) printf(", ");
        if ((j + 1) % 8 == 0) printf("\n   ");
    }
    printf("]\n\n");

    printf("  Output 2 (v3_0, shape: ):\n");
    printf("  [");
    for (int j = 0; j < 1.0; j++) {
        printf("%.6f", output_data[2][j]);
        if (j < 1.0 - 1) printf(", ");
        if ((j + 1) % 8 == 0) printf("\n   ");
    }
    printf("]\n\n");

    printf("\n");

    // Clean up
    printf("Cleaning up memory...\n");
    for (int i = 0; i < 2; i++) {
        free(input_data[i]);
    }
    for (int i = 0; i < 3; i++) {
        free(output_data[i]);
    }

    printf("Program completed successfully.\n");
    return 0;
}
